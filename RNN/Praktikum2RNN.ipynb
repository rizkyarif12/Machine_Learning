{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rizkyarif12/Machine_Learning/blob/main/RNN/Praktikum2RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31009372-5996-49b5-83b0-52fd928a73bd",
      "metadata": {
        "id": "31009372-5996-49b5-83b0-52fd928a73bd"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84d260a2-a661-4809-80d4-e3094635b054",
      "metadata": {
        "id": "84d260a2-a661-4809-80d4-e3094635b054",
        "outputId": "1a4ca88f-b7a2-4a2b-8355-6b6d85f00286"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "\u001b[1m1115394/1115394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7f32879-76b1-444c-abd7-feb199156070",
      "metadata": {
        "id": "e7f32879-76b1-444c-abd7-feb199156070",
        "outputId": "a41a81be-1c5d-4657-b042-1f92f5762c2b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "150458bd-5067-44be-b634-5275a5f089b0",
      "metadata": {
        "id": "150458bd-5067-44be-b634-5275a5f089b0",
        "outputId": "fb63ab12-975a-4c4e-97b2-3bb3bf6b11bc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Take a look at the first 250 characters in text\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "29120769-09b8-48aa-9a07-814bca001970",
      "metadata": {
        "id": "29120769-09b8-48aa-9a07-814bca001970",
        "outputId": "55ccb599-854a-4672-d527-d19473e92efd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# The unique characters in the file\n",
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4d95bd3b-2c09-423c-85e9-01c2c8d3c84c",
      "metadata": {
        "id": "4d95bd3b-2c09-423c-85e9-01c2c8d3c84c",
        "outputId": "05104f71-7d22-4c19-c9c0-611da64e2dd6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "501818bb-26ea-4b62-85d5-2bf71342a0a7",
      "metadata": {
        "id": "501818bb-26ea-4b62-85d5-2bf71342a0a7"
      },
      "outputs": [],
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "vocabulary=list(vocab), mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44e341b8-127e-409b-a67f-26e7070b8e95",
      "metadata": {
        "id": "44e341b8-127e-409b-a67f-26e7070b8e95",
        "outputId": "3481481c-f15b-4c7f-ae14-b6d57122bf52"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7d8144b-9b37-474d-b013-260684a05d01",
      "metadata": {
        "id": "b7d8144b-9b37-474d-b013-260684a05d01"
      },
      "outputs": [],
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01c57088-bfcb-41dd-9517-1995ed098c36",
      "metadata": {
        "id": "01c57088-bfcb-41dd-9517-1995ed098c36",
        "outputId": "56e480be-b9d8-4083-9da9-ae5939cd04a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb75704a-944f-43bc-8ae9-299a58bd388b",
      "metadata": {
        "id": "cb75704a-944f-43bc-8ae9-299a58bd388b",
        "outputId": "1f80e1ed-1f3f-478f-c768-23a1765f7afc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c34549e7-c3bf-4eca-b5df-c415d0c4ebd0",
      "metadata": {
        "id": "c34549e7-c3bf-4eca-b5df-c415d0c4ebd0"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0e5a996-9b57-4444-9769-560296dbe90b",
      "metadata": {
        "id": "a0e5a996-9b57-4444-9769-560296dbe90b",
        "outputId": "fb579e98-8fef-4b0b-af0e-7e9dcf4178b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a994e335-7335-49d6-826d-0fc69fd1c0b2",
      "metadata": {
        "id": "a994e335-7335-49d6-826d-0fc69fd1c0b2"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ea73e4c1-857c-423b-9787-f722dc1b813f",
      "metadata": {
        "id": "ea73e4c1-857c-423b-9787-f722dc1b813f",
        "outputId": "77c6184c-4ab4-4554-b414-d15df9f8e796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ebc2ed4-e482-4421-a9b8-2ab5491c8baf",
      "metadata": {
        "id": "5ebc2ed4-e482-4421-a9b8-2ab5491c8baf"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "337155aa-0ec9-4888-8ae4-7c9c6b7ff26f",
      "metadata": {
        "id": "337155aa-0ec9-4888-8ae4-7c9c6b7ff26f",
        "outputId": "e4d7f965-4a54-45a4-e788-45c47f98c5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2dbbca-c735-4442-a9c5-edf6c0e6872e",
      "metadata": {
        "id": "0a2dbbca-c735-4442-a9c5-edf6c0e6872e",
        "outputId": "6482dcf7-6ec7-4e34-bfc2-ae39baf73c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2923d63-0592-4cb7-a87b-32c4ffca1e42",
      "metadata": {
        "id": "b2923d63-0592-4cb7-a87b-32c4ffca1e42"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c1617f43-93cf-4c12-9517-e0baa0f36ae3",
      "metadata": {
        "id": "c1617f43-93cf-4c12-9517-e0baa0f36ae3",
        "outputId": "003fb56e-afc6-4c2a-feb4-885673733b89"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9326d20-f414-4bb2-b5ed-e9d4caeb3a25",
      "metadata": {
        "id": "a9326d20-f414-4bb2-b5ed-e9d4caeb3a25"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "495257a1-0bb4-4ea7-82c2-2964c4e7d5c3",
      "metadata": {
        "id": "495257a1-0bb4-4ea7-82c2-2964c4e7d5c3",
        "outputId": "9d8bbe42-bdff-4f23-fe34-1f1dd19ccfd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b5ac7bca-fdcf-4e63-adaf-243c7a82bbdf",
      "metadata": {
        "id": "b5ac7bca-fdcf-4e63-adaf-243c7a82bbdf",
        "outputId": "2477b5d7-29bd-4287-d205-40185f15c441"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size to shuffle the dataset\n",
        "# (TF data is designed to work with possibly infinite sequences,\n",
        "# so it doesn't attempt to shuffle the entire sequence in memory. Instead,\n",
        "# it maintains a buffer in which it shuffles elements).\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "838fa6f8-a155-4054-9525-bf7aa8a5311e",
      "metadata": {
        "id": "838fa6f8-a155-4054-9525-bf7aa8a5311e"
      },
      "outputs": [],
      "source": [
        "# Length of the vocabulary in StringLookup Layer\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# The embedding dimension\n",
        "embedding_dim = 256\n",
        "\n",
        "# Number of RNN units\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "414e4330-101c-4667-a740-c16202f8230e",
      "metadata": {
        "id": "414e4330-101c-4667-a740-c16202f8230e"
      },
      "outputs": [],
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "        super(MyModel, self).__init__()\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True)\n",
        "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "    def call(self, inputs, states=None, return_state=False, training=False):\n",
        "        x = self.embedding(inputs)\n",
        "        if states is None:\n",
        "            states = self.gru.get_initial_state(batch_size=tf.shape(inputs)[0])\n",
        "        x, states = self.gru(x, initial_state=states, training=training)\n",
        "        x = self.dense(x)\n",
        "\n",
        "        if return_state:\n",
        "            return x, states\n",
        "        else:\n",
        "            return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6c6f867-e489-471e-8d8b-b3193038bbd5",
      "metadata": {
        "id": "b6c6f867-e489-471e-8d8b-b3193038bbd5"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c6d6ea6-0950-4c3d-9a10-35e727b480c3",
      "metadata": {
        "id": "4c6d6ea6-0950-4c3d-9a10-35e727b480c3",
        "outputId": "b62f29fa-aac2-449f-b1ae-ece4c1246e64"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01474cf1-e784-4950-bc58-5c89f259b9c9",
      "metadata": {
        "id": "01474cf1-e784-4950-bc58-5c89f259b9c9",
        "outputId": "74f2a456-902e-4c69-dbc8-4d260e82a977"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"my_model\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"my_model\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>)                       │ ((<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>), (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,938,304</span> │\n",
              "│                                 │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>))                 │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">66</span>)          │        <span style=\"color: #00af00; text-decoration-color: #00af00\">67,650</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │        \u001b[38;5;34m16,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ gru (\u001b[38;5;33mGRU\u001b[0m)                       │ ((\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m1024\u001b[0m), (\u001b[38;5;34m64\u001b[0m, │     \u001b[38;5;34m3,938,304\u001b[0m │\n",
              "│                                 │ \u001b[38;5;34m1024\u001b[0m))                 │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m66\u001b[0m)          │        \u001b[38;5;34m67,650\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,022,850</span> (15.35 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,022,850\u001b[0m (15.35 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,022,850</span> (15.35 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,022,850\u001b[0m (15.35 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "700a0e03-cfea-4b88-9936-e34da534d350",
      "metadata": {
        "id": "700a0e03-cfea-4b88-9936-e34da534d350"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "652a13b8-0b41-4e21-b5d4-d73153ca10a6",
      "metadata": {
        "id": "652a13b8-0b41-4e21-b5d4-d73153ca10a6",
        "outputId": "4b30eca3-62d7-4c99-c64e-aeaab00d7df0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([11, 60, 42, 60, 61,  9, 21, 28, 46, 58, 62, 55, 51,  9, 64, 25, 33,\n",
              "       28,  3, 44, 14, 63, 63, 26, 14, 61,  3, 49, 59,  4, 57,  8, 11, 48,\n",
              "       12, 28, 61, 54, 10, 13, 29, 37,  9,  6, 19,  3, 50, 26, 62, 42, 52,\n",
              "       26, 22, 15, 44, 36, 60, 18, 51, 26, 19, 29, 12, 13, 32, 56, 31, 62,\n",
              "       59, 26, 36, 63, 28, 44, 34,  1, 43, 24, 60, 48, 25,  3, 39, 10,  3,\n",
              "       47, 20, 48,  1, 60, 39, 47, 35, 39, 55, 35, 62, 38, 52, 19])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "61220de8-fdbf-4127-ad32-d3fb18e4c805",
      "metadata": {
        "id": "61220de8-fdbf-4127-ad32-d3fb18e4c805",
        "outputId": "0d78cd7a-9dd7-4e71-b7d0-314a7b97f87b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b'death aside, and with the other sends\\nIt back to Tybalt, whose dexterity,\\nRetorts it: Romeo he cries'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\":ucuv.HOgswpl.yLTO!eAxxMAv!jt$r-:i;Ovo3?PX.'F!kMwcmMIBeWuElMFP;?SqRwtMWxOeU\\ndKuiL!Z3!hGi\\nuZhVZpVwYmF\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "44d45973-8ddf-4836-8560-0d92ae7b079a",
      "metadata": {
        "id": "44d45973-8ddf-4836-8560-0d92ae7b079a"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99bbc659-16fd-4a71-a8bd-ecec821e6e02",
      "metadata": {
        "id": "99bbc659-16fd-4a71-a8bd-ecec821e6e02",
        "outputId": "155750a9-21eb-4d8b-f4b1-b28fd0356f12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.190561, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "84f17851-06e1-43be-acac-e8f7ea2a63e1",
      "metadata": {
        "id": "84f17851-06e1-43be-acac-e8f7ea2a63e1",
        "outputId": "fb938d8c-6610-457c-a4b6-d74d14360e4c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "np.float32(66.05983)"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f765320-d490-4068-823e-116c42699aeb",
      "metadata": {
        "id": "2f765320-d490-4068-823e-116c42699aeb"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05c58b39-74c9-48d3-8dc5-4fd90754457b",
      "metadata": {
        "id": "05c58b39-74c9-48d3-8dc5-4fd90754457b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}.weights.h5\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52fdf3a8-ad57-4f11-9ef3-c365ab01e12a",
      "metadata": {
        "id": "52fdf3a8-ad57-4f11-9ef3-c365ab01e12a"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f38bd5d7-e59e-4cc1-8755-a7ae33728145",
      "metadata": {
        "id": "f38bd5d7-e59e-4cc1-8755-a7ae33728145",
        "outputId": "1f1798a4-da27-41b1-8fa0-30c53aeaeeba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 554ms/step - loss: 3.0509\n",
            "Epoch 2/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 551ms/step - loss: 1.9164\n",
            "Epoch 3/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 1.6299\n",
            "Epoch 4/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 549ms/step - loss: 1.4836\n",
            "Epoch 5/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 548ms/step - loss: 1.3933\n",
            "Epoch 6/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 549ms/step - loss: 1.3308\n",
            "Epoch 7/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 549ms/step - loss: 1.2809\n",
            "Epoch 8/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 550ms/step - loss: 1.2385\n",
            "Epoch 9/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 549ms/step - loss: 1.1924\n",
            "Epoch 10/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 551ms/step - loss: 1.1515\n",
            "Epoch 11/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 1.1114\n",
            "Epoch 12/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 551ms/step - loss: 1.0691\n",
            "Epoch 13/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 551ms/step - loss: 1.0209\n",
            "Epoch 14/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 0.9765\n",
            "Epoch 15/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 0.9297\n",
            "Epoch 16/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 549ms/step - loss: 0.8758\n",
            "Epoch 17/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 0.8251\n",
            "Epoch 18/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 553ms/step - loss: 0.7767\n",
            "Epoch 19/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 0.7280\n",
            "Epoch 20/20\n",
            "\u001b[1m172/172\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 552ms/step - loss: 0.6810\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c754303-b8c2-4d34-98c1-36542cfb5cf2",
      "metadata": {
        "id": "0c754303-b8c2-4d34-98c1-36542cfb5cf2"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "326eff70-1466-40c3-a1a6-4df62ec3a50a",
      "metadata": {
        "id": "326eff70-1466-40c3-a1a6-4df62ec3a50a"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "75c464a2-d22b-46d1-a61d-7c4500d91c36",
      "metadata": {
        "id": "75c464a2-d22b-46d1-a61d-7c4500d91c36",
        "outputId": "d827d542-1f66-45f5-9073-3d0d18a693ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Not my good lord.\n",
            "\n",
            "MAMILLIUS:\n",
            "You are almost least.\n",
            "\n",
            "Lord:\n",
            "Even as a warrant in atary\n",
            "The heavens, espayers all our sights,\n",
            "I have borne a brand in justice, when\n",
            "They are officed at the winds of sort. Now,\n",
            "He promised us, the more hither of his\n",
            "minister. Provosious flood!\n",
            "Both he had lived by new care?\n",
            "Or else before the wind and stored grais of truth,\n",
            "Can currond me in mine spite, givething!\n",
            "The oath we have strengthen myself a blow.\n",
            "\n",
            "HENRY BOLINGBROKE:\n",
            "Go to, my good lord.\n",
            "\n",
            "BRAKENBURY:\n",
            "I confess it, must I tell her hence.\n",
            "\n",
            "QUEEN ELIZABETH:\n",
            "My lands, my lords, God save your manners to his memony!\n",
            "To have you beauty, matam, well, Pompey;\n",
            "but the bleeder of their lives bad him,\n",
            "Did ever reign showalt father Hather,\n",
            "The treasons made me acking my patted blood,\n",
            "He should not die the while; while it would speak,\n",
            "Near to thy grave: all the which you pluck\n",
            "apparent proves to know it: yet to-day, be those\n",
            "That shate our blood up in reckoning.\n",
            "Now Music To another day,\n",
            "That love was kneel by  \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.560591697692871\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "df61b55b-1c74-4229-9bf8-6d55faebd6e7",
      "metadata": {
        "id": "df61b55b-1c74-4229-9bf8-6d55faebd6e7",
        "outputId": "bcd8a3c6-b991-428b-bfe1-8f3a19c59e29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nThis news is rather without all in thee.\\n\\nGREEN:\\nWell, I must to Coventry.\\n\\nCAPULET:\\nSend for that with breaths, which shall beasts sound\\nThan began? We'll you read\\nPresently to know the brain:\\nAway, sir; for, he should, in dead minister\\nTo tormender when he shall be dancedon'd stones,\\nAnd knew she weeps than should be how aught him:\\nI have done a body meat together.\\n\\nVINCENTIO:\\nGo fetch him, or have is lesson'd.\\n\\nPRINCE EDWARD:\\nWhen Clarence defend and sea it,\\nOr, brother, he smiles and\\nBred a fork as a bastard below,\\nAnd will not hear it. Hast thou believe\\nTo make our state to England? wherefore?\\n\\nBIONDELLO:\\nHe is almost too?\\n\\nELBOW:\\nAy, sir; wherefore weep my own mouth?\\n\\nSecond Murderer:\\nThe blood of that breast of its one assugh,\\nWhen friends as wears at any wounds with willings of thine:\\nThough most adump in falch Diamon. Lucentio,\\nYour Citizens' seas, and there who sins our general:' betide\\nForebrais her to him: let's part of that hemity.\\nGood, get him hereaft, till thou go alon\"\n",
            " b\"ROMEO:\\nThrow up his love; and leave him with libert\\nWould I not see, the impress of a bled,\\nBraught for broking his the cause, and ne'er been\\nThey may be the glasses. Thou lipst--\\nTo shame consent, in a wonder shares the townge--hop art thou withdraw 'twas as clouded\\nbehind the sea for brain'd soul-siggery:\\nAnd brave the most particulain treasupt against his flight;\\nAnd in their shepherd's dreadful brother,\\nI dreamt, yet I'll turn yon perform'd:\\nHow far from smooths there not befalting horries?\\n\\nRATCLUCIO:\\nRomeo is banished.\\n\\nROMEO:\\nProud death, wherefore stay? not whence are now for fear.\\nWhat is't your honour for that word?\\n\\nMENENIUS:\\nHear me.\\nGood morrow o' the reason stoop:\\nNo sick man's approbation.\\n\\nPROSPERO:\\nWhat, when, ey, pill'd, know'd him,\\nWhen I bid thee setical of finger,\\nEre stock'd on the all-herith-ilder, and\\nunstail'd wars, yea, and my Lord of York\\nWe well breathed ought for mean: think you what we are\\nused us partly a rip: adieu, mark me.\\nWhen, ha? thou art not Gaunt!' and \"\n",
            " b\"ROMEO:\\nGrave some of him: since we are now giddy for gold\\nthat threaten desire thee with mirrordina.\\nBut where's the ratue is broke his friends. Your brother's lands\\nIs death in idle too fools!\\nWhat art thou yie?\\nThou shalt congeal pinolant farewell.\\n\\nFRIAR LAURENCE:\\nWhat may have made me a husband?\\n\\nLeOD WARWICK:\\nNay, he's a loathed blood Kate of thy life:\\nThis brain depose,--\\n\\nGLOUCESTER:\\nGo perform, and say it waste thyself, and sunger best.\\n\\nROMEO:\\nCartliff; the flies of Signior Gremio.\\n\\nFRIAR LAURENCE:\\nWere not, mistress Overfore's name, strong and eyes, I was said\\nWith Bolingbroke, to ride and the love I part.\\n\\nKING RICHARD II:\\nWe were an heavy head and dull away me from\\nthe precious treasury and a man of warl\\nOffer almost things; forward, or the rest.\\n\\nKING HENRY VI:\\nFor me, that I must bear a pursuit, crack'd\\nOf golden use if the boy with in\\nthe act. Thursday next, and over their\\nlabour: some accused in her\\nUntil they will bound in with him.\\n\\nKING HENRY VI:\\nWas ever man us now to say\"\n",
            " b\"ROMEO:\\nThus within me from the tall Cleam\\nFor ten time madest know your feasts are pardon.\\n\\nNORSOLY SORGEL:\\nNow York and my good lord mayor, when God's sake.\\n\\nDUKE VINCENTIO:\\nThat shall we do? saw't poor Juliet,\\nAs thou said envy in thy companion?\\n\\nKING RICHARD III:\\nO, good heartusal!\\nI beseech your hands, and death, you must return.\\nFarewell: good swift, comfort and straight doth him;\\nAll husbunds all uncleanlined to die.\\nI beseech you mean to blemish, you rogues,\\nHave I not near the temped moringal\\nHow takes from me this mummer's part-servarent\\nTo make our mercy instantly done;\\nHe makes a Christian pinotyer cannot live,\\nYour aunting, life and paved bestward.\\nCome, learn it away till no more\\nTo be your king, myself and me.\\nWhat muddy portune! He's one hour to the keys.\\n\\nWARWICK:\\nAlas, alas!\\nWhat a misleave of the easy days,\\nSince thou dreadful man,--what if aught\\nbe her man to do't, acquaint her he, are hereatter:\\nEven now,--will be a fong fall of door. There's one\\nWhen she do walks at us w\"\n",
            " b\"ROMEO:\\nThe earle the humbler of the numbers\\nNo more may keep the ben of livery.\\n\\nNurse:\\nEven of that janner, in the better of that royal'd\\nWhere all the world--hourd in the miracle,\\nI may be thought no less import from head\\nAs vain on would keep my steck again,\\nOver law was never given sovereign.\\nBut thou art nurse, to wish the falcon's and old\\nFriends at very roath, early 'em; come little words,\\nPearer with him, Seiging here, and leave us.\\n\\nALONSO:\\nThou wilt fall backward.\\n\\nDUKE VINCENTIO:\\nNot I, believe me: thou art denied?\\nWe may not, but the lustisy cries and prayers\\nToo should have poison'd with falsehood e'er again;\\nThe rather of Clarence our conquer'd books,\\nAnd both prodiguld through the crown to keep these shape\\nLiving too fool in the wits; yea, sapred,\\nDile, and resolve your saints, know mind\\neither one read for your nine an hour ago, if\\nill bedash'd; what effect a play,\\nYou must hear it at.\\n\\nANTIGONUS:\\nThat I'll stay by forth of you.\\n\\nROMEO:\\nCourage, have we heard to him?\\n\\nAUTOLYC\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 2.5538103580474854\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "270413d5-c5c2-4070-9b07-146e45dc0a51",
      "metadata": {
        "id": "270413d5-c5c2-4070-9b07-146e45dc0a51",
        "outputId": "4d1fc32c-0aa3-4182-ad02-9ed60b680d02"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: one_step/assets\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6d64b659-b939-43fc-8670-d43c0121a2d7",
      "metadata": {
        "id": "6d64b659-b939-43fc-8670-d43c0121a2d7",
        "outputId": "9f56834c-7b30-48c4-9d40-5fccc128ea7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "The rapes of her queen, we both,\n",
            "went from his sword shorn, take thousand unto the world;\n",
            "To take o\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}